{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wxy/.conda/envs/sac3/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from evaluator_fast import Evaluate\n",
    "from consistency_checker_fast import SemanticConsistnecyCheck\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "import openai\n",
    "import json\n",
    "import openai\n",
    "# from sklearn.metrics import precision_recall_curve, auc, classification_report, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# api_key = \n",
    "# openai.api_key = 'sk-S6lJtVwrvPOyWV9L11DcFb729bC6488e95493d368bF5B4A5'\n",
    "# qa_data = load_dataset(\"json\", data_files=\"dataset/hotpotQA_halu.json\")\n",
    "\n",
    "def hallucination_score(question, target_answer, model, num_samples):\n",
    "    \n",
    "    # llm evaluation\n",
    "    llm_evaluate = Evaluate(model=model)\n",
    "    scc = SemanticConsistnecyCheck(model=model)\n",
    "    # fast self-evaluation\n",
    "    fast_self_responses = llm_evaluate.self_evaluate_api(self_question = question, temperature = 1.0, self_num = num_samples)\n",
    "    # fast consistency checker \n",
    "    fast_consistency_res = scc.score_scc_api(question, target_answer, candidate_answers = fast_self_responses, temperature = 0.0)\n",
    "    \n",
    "    return fast_consistency_res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "halu_score_all = []\n",
    "true_label = []\n",
    "\n",
    "import os\n",
    "# start = 0\n",
    "# end = 20\n",
    "# data_name = 'hotpot_qa'\n",
    "data_name = 'gsm8k'\n",
    "# model_name = 'vicuna-7b'\n",
    "# model_name = 'llama2-7b-chat-hf'\n",
    "# model_name = 'Mistral-7B-Instruct-v0.2'\n",
    "model_name = 'vicuna-13b'\n",
    "\n",
    "test_path = f'/home/wxy/project/hallucination_predict_by_prompt/data/datasets/gsm8k/0shot/output/0shot/gsm8k_{model_name}_1_sample_0shot_test.json'\n",
    "output_file = f'./result/result_{data_name}_{model_name}_v2.txt'\n",
    "output_time_file = f'./result/time_cost_{data_name}_{model_name}_v2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\t0.8\t1\t5.6967\n",
      "801\t0.5\t0\t5.0160\n",
      "802\t0.8\t1\t6.4302\n",
      "803\t0.0\t0\t4.4819\n",
      "804\t0.1\t1\t4.1672\n",
      "805\t0.3\t1\t6.4814\n",
      "806\t0.8\t1\t4.3321\n",
      "807\t0.0\t0\t4.5339\n",
      "808\t0.6\t1\t3.9644\n",
      "809\t0.0\t0\t4.2480\n",
      "810\t0.1\t1\t5.6174\n",
      "811\t0.5\t1\t6.0279\n",
      "812\t0.0\t0\t3.7941\n",
      "813\t0.2\t1\t4.0396\n",
      "814\t0.8\t1\t6.3681\n",
      "815\t0.4\t1\t5.6627\n",
      "816\t0.0\t1\t3.7510\n",
      "817\t0.8\t1\t4.7182\n",
      "818\t0.6\t1\t4.9839\n",
      "819\t0.4\t1\t4.7687\n",
      "820\t0.2\t1\t5.9346\n",
      "821\t0.9\t1\t4.1160\n",
      "822\t0.7\t1\t4.7388\n",
      "823\t0.7\t1\t4.7752\n",
      "824\t1.0\t1\t5.7781\n",
      "825\t0.6\t1\t3.7763\n",
      "826\t0.0\t0\t5.0949\n",
      "827\t0.1\t1\t5.6508\n",
      "828\t0.0\t0\t4.1867\n",
      "829\t0.5\t1\t5.2901\n",
      "830\t0.2\t1\t5.2412\n",
      "831\t0.9\t1\t4.6728\n",
      "832\t0.4\t1\t4.3951\n",
      "833\t0.3\t1\t4.7476\n",
      "834\t0.0\t0\t5.1916\n",
      "835\t0.8\t1\t5.5953\n",
      "836\t1.0\t1\t3.3782\n",
      "837\t0.1\t0\t3.0947\n",
      "838\t0.0\t0\t6.2313\n",
      "839\t1.0\t1\t4.0311\n",
      "840\t0.6\t1\t5.8620\n",
      "841\t0.0\t0\t4.4196\n",
      "842\t0.0\t0\t3.4076\n",
      "843\t0.8\t1\t4.8106\n",
      "844\t0.0\t0\t5.5187\n",
      "845\t0.5\t1\t4.2601\n",
      "846\t0.7\t1\t8.0139\n",
      "847\t0.1\t0\t4.0481\n",
      "848\t0.0\t0\t6.4670\n",
      "849\t0.8\t1\t3.8253\n",
      "850\t0.1\t1\t7.1441\n",
      "851\t0.8\t1\t7.2543\n",
      "852\t0.1\t0\t3.6176\n",
      "853\t0.6\t1\t3.5376\n",
      "854\t0.4\t1\t7.9208\n",
      "855\t0.5\t1\t5.2348\n",
      "856\t1.0\t1\t3.9656\n",
      "857\t0.0\t0\t6.4758\n",
      "858\t0.0\t0\t4.2144\n",
      "859\t1.0\t1\t4.0087\n",
      "860\t0.0\t0\t5.7728\n",
      "861\t0.0\t0\t4.5945\n",
      "862\t0.7\t1\t7.2149\n",
      "863\t0.1\t0\t3.9301\n",
      "864\t0.2\t1\t11.3600\n",
      "865\t0.9\t1\t4.6648\n",
      "866\t0.0\t1\t6.4358\n",
      "867\t0.7\t1\t3.9061\n",
      "868\t0.7\t1\t5.9748\n",
      "869\t0.9\t1\t5.9815\n",
      "870\t0.4\t1\t6.7846\n",
      "871\t0.4\t1\t6.1895\n",
      "872\t0.9\t1\t4.9407\n",
      "873\t0.1\t0\t4.8325\n",
      "874\t1.0\t1\t7.7605\n",
      "875\t1.0\t1\t4.2646\n",
      "876\t0.1\t0\t4.0095\n",
      "877\t0.3\t1\t3.7924\n",
      "878\t0.0\t0\t4.2332\n",
      "879\t0.2\t1\t4.2410\n",
      "880\t0.0\t0\t6.9805\n",
      "881\t0.6\t1\t4.3233\n",
      "882\t0.0\t0\t3.7774\n",
      "883\t0.6\t1\t5.3841\n",
      "884\t0.4\t1\t5.1224\n",
      "885\t0.4\t0\t3.3615\n",
      "886\t0.5\t1\t4.1846\n",
      "887\t0.8\t1\t3.4924\n",
      "888\t0.1\t1\t3.3328\n",
      "889\t0.1\t0\t3.1282\n",
      "890\t0.1\t1\t3.8482\n",
      "891\t0.0\t0\t4.5933\n",
      "892\t0.5\t1\t4.1102\n",
      "893\t0.0\t0\t3.4876\n",
      "894\t0.1\t1\t4.9779\n",
      "895\t0.0\t0\t4.1981\n",
      "896\t0.1\t1\t5.2937\n",
      "897\t0.2\t1\t6.7207\n",
      "898\t1.0\t1\t3.6765\n",
      "899\t0.7\t1\t7.3227\n",
      "900\t1.0\t1\t5.7967\n",
      "901\t0.9\t1\t3.6737\n",
      "902\t0.0\t0\t3.3019\n",
      "903\t0.0\t0\t4.0556\n",
      "904\t0.0\t0\t4.5357\n",
      "905\t1.0\t1\t3.0455\n",
      "906\t0.1\t1\t3.6815\n",
      "907\t0.4\t1\t6.2014\n",
      "908\t0.1\t1\t5.6965\n",
      "909\t1.0\t1\t3.1054\n",
      "910\t0.0\t0\t4.5580\n",
      "911\t0.2\t1\t4.2708\n",
      "912\t1.0\t1\t3.9965\n",
      "913\t1.0\t1\t4.6295\n",
      "914\t0.3\t1\t6.4365\n",
      "915\t0.0\t0\t5.0545\n",
      "916\t0.8\t1\t4.9985\n",
      "917\t0.8\t1\t4.1741\n",
      "918\t0.0\t1\t4.5239\n",
      "919\t1.0\t1\t5.5042\n",
      "920\t0.0\t0\t5.1076\n",
      "921\t0.2\t0\t3.7816\n",
      "922\t0.9\t1\t7.8526\n",
      "923\t1.0\t1\t5.6624\n",
      "924\t0.1\t0\t2.8289\n",
      "925\t0.1\t1\t5.5880\n",
      "926\t0.1\t1\t6.5022\n",
      "927\t0.0\t0\t4.2687\n",
      "928\t0.7\t1\t6.6936\n",
      "929\t0.6\t1\t7.2326\n",
      "930\t0.0\t0\t4.4465\n",
      "931\t0.6\t1\t5.0200\n",
      "932\t1.0\t1\t3.5143\n",
      "933\t0.1\t0\t5.0660\n",
      "934\t0.1\t1\t5.4962\n",
      "935\t0.0\t0\t4.7865\n",
      "936\t1.0\t1\t3.5106\n",
      "937\t0.7\t1\t4.9656\n",
      "938\t0.8\t1\t4.8713\n",
      "939\t0.0\t1\t5.5876\n",
      "940\t0.7\t1\t6.2652\n",
      "941\t0.6\t1\t4.7928\n",
      "942\t0.0\t1\t3.9602\n",
      "943\t0.1\t1\t6.2246\n",
      "944\t0.1\t0\t4.1182\n",
      "945\t0.8\t1\t3.2563\n",
      "946\t1.0\t1\t3.7170\n",
      "947\t0.5\t1\t5.1305\n",
      "948\t0.7\t1\t4.5515\n",
      "949\t0.5\t1\t7.3267\n",
      "950\t0.0\t0\t6.0311\n",
      "951\t0.5\t1\t4.5040\n",
      "952\t1.0\t1\t3.9186\n",
      "953\t0.0\t0\t6.2884\n",
      "954\t1.0\t1\t7.5330\n",
      "955\t0.0\t0\t5.2904\n",
      "956\t0.0\t0\t4.0396\n",
      "957\t0.7\t0\t7.8054\n",
      "958\t0.0\t0\t3.8376\n",
      "959\t0.0\t0\t6.0344\n",
      "960\t1.0\t1\t3.0536\n",
      "961\t0.2\t0\t3.8681\n",
      "962\t1.0\t1\t8.6409\n",
      "963\t0.7\t1\t5.3831\n",
      "964\t0.1\t1\t5.9804\n",
      "965\t0.8\t1\t4.7396\n",
      "966\t1.0\t1\t5.5970\n",
      "967\t0.9\t1\t8.0032\n",
      "968\t0.1\t0\t5.0362\n",
      "969\t0.0\t0\t4.5671\n",
      "970\t0.9\t1\t4.7951\n",
      "971\t1.0\t1\t3.3289\n",
      "972\t0.9\t1\t6.6244\n",
      "973\t0.4\t1\t6.3390\n",
      "974\t0.0\t1\t5.2056\n",
      "975\t0.0\t0\t4.1701\n",
      "976\t1.0\t1\t4.7337\n",
      "977\t0.0\t1\t3.4396\n",
      "978\t0.4\t1\t4.2999\n",
      "979\t0.1\t1\t4.3504\n",
      "980\t0.4\t1\t5.3182\n",
      "981\t0.0\t0\t5.2412\n",
      "982\t0.3\t0\t6.1908\n",
      "983\t0.5\t1\t4.3049\n",
      "984\t1.0\t1\t2.9763\n",
      "985\t1.0\t1\t3.0194\n",
      "986\t0.8\t1\t5.3543\n",
      "987\t1.0\t1\t6.8078\n",
      "988\t0.0\t0\t3.9530\n",
      "989\t0.9\t1\t4.2111\n",
      "990\t0.3\t1\t4.4326\n",
      "991\t1.0\t1\t6.6945\n",
      "992\t0.2\t1\t6.1721\n",
      "993\t0.0\t0\t5.7324\n",
      "994\t0.5\t1\t7.9326\n",
      "995\t0.9\t1\t5.6717\n",
      "996\t0.0\t0\t4.6259\n",
      "997\t0.0\t0\t5.4571\n",
      "998\t0.0\t1\t4.5217\n",
      "999\t1.0\t1\t4.1040\n"
     ]
    }
   ],
   "source": [
    "model = 'gpt-3.5-turbo'\n",
    "num_samples = 10\n",
    "d_time = {}\n",
    "with open(test_path, 'r') as f, open(output_file, 'a') as w, open(output_time_file, 'a') as t:\n",
    "    for line in f.readlines():\n",
    "        d = json.loads(line.strip())\n",
    "        q_id = d['id']\n",
    "        target_answer =  d['predict']\n",
    "        label = d['label']\n",
    "        question = d['prompt'] \n",
    "        t0 = time.time()\n",
    "        halu_score = hallucination_score(question, target_answer, model, num_samples)\n",
    "        time_cost = time.time() - t0\n",
    "        w.write(f'{q_id}\\t{halu_score}\\t{label}\\n')\n",
    "        print(f'{q_id}\\t{halu_score}\\t{label}\\t{time_cost:.4f}')\n",
    "        t.write(f'{q_id}\\t{time_cost:.4f}\\n')\n",
    "\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wxy_llm_sample",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
